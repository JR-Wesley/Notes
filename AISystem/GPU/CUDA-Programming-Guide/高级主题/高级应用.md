---
dateCreated: 2025-07-06
dateModified: 2025-08-14
---
# Float 4

<a href="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/">Grid stride loops</a>

<a href="https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/">float 4</a>

### 三、**高级并行技术（精通）**

**目标**：掌握多 GPU 协作、流并行、动态并行等复杂技术

#### 1. **多 GPU 编程**

- **设备管理**：`cudaSetDevice`、`cudaGetDeviceCount`
- **P2P 内存访问**：
- **任务划分策略**：按数据分块、按功能分阶段

#### 2. **异步流并行**

- **流（Stream）**：独立的执行队列，实现计算与数据传输重叠

    ```cpp
    cudaStream_t stream;
    cudaStreamCreate(&stream);
    
    // 异步操作
    cudaMemcpyAsync(d_a, h_a, size, cudaMemcpyHostToDevice, stream);
    kernel<<<grid, block, 0, stream>>>(d_a, d_b, d_c);
    cudaMemcpyAsync(h_c, d_c, size, cudaMemcpyDeviceToHost, stream);
    
    cudaStreamSynchronize(stream);
    cudaStreamDestroy(stream);
    ```

#### 3. **动态并行**

- **GPU 内递归计算**：

    ```cpp
    __global__ void recursiveKernel(int depth) {
        if (depth > 0) {
            // 子核函数调用
            recursiveKernel<<<1, 1>>>(depth - 1);
        }
        // 处理数据
    }
    ```

#### 4. **CUDA 与其他技术结合**

- **OpenMP+CUDA**：混合 CPU-GPU 并行
- **CUDA+MPI**：分布式多节点 GPU 计算
- **CUDA 与深度学习框架**：自定义算子开发
- **CUDA 库**：
    - cuBLAS（线性代数）、cuDNN（深度学习）、cuFFT（快速傅里叶变换）等，直接调用预优化库加速常见计算。
- **多 GPU 编程**：
    - 使用 `cudaSetDevice()` 管理多个 GPU，通过 `nccl`（NVIDIA Collective Communications Library）实现 GPU 间通信。
- **Python 接口**：
    - **PyCUDA**：直接在 Python 中调用 CUDA 核函数。
    - **Numba**：通过 JIT 编译 Python 函数为 CUDA 代码，简化开发。
